The files "data0.h5", "data1.h5", ..., "data19.h5" are virtual dataset. There are 5120 simulated point cloud scenes totally, and there are 256 scene point clouds in each file. The data in the first sixteen files are used as the training dataset, while that in the last four file are used as the test dataset.

The files "data_r0.h5", "data_r1.h5", "data_r2.h5", "data_r3.h5" and "data_r4.h5" are real dataset. There are 800 point clouds captured by depth cameras in industrial scenes, and there are 160 scene point clouds in each file. The data in the first four files are used as the training dataset, while that in the last file are used as the test dataset.

In these files, each scene point cloud contains 8192 points. However, only 2048 points are needed in the experiment, so random down sampling will be adopted in the experiment. In these point cloud data, the points in the scenes will be marked into 7 categories: background object, robot 1, robot 2, workpiece, human, AGV, and other flying obstacle. The objects of these 7 categories are labeled with numbers from 0 to 6.

In these files, the group "data" are the actual point clouds, and the group "scene" are the corresponding simulated point clouds. The group "label" are the corresponding segmentation labels. The group "joint" is the corresponding robot joint posture angle in the scene, and the change in the sixth joint angle of the robot has little impact on the point cloud. Therefore, only the posture angles of the first five joints of the robot are recorded here. There are two robots in the scene, so the robot joint posture angle information in each scene is a ten dimensional vector. 
